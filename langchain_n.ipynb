{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['OPEN_API_KEY']='sk-aqARNNOsDM8RSkodhdhhdhdhdrY4z0SQed76g0i'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm=OpenAI(openai_api_key=os.environ['OPEN_API_KEY'],temperature=0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "The capital of India is New Delhi.\n"
     ]
    }
   ],
   "source": [
    "text=\"What is capital of India\"\n",
    "print(llm.predict(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"]=\"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import HuggingFaceHub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\basha\\LLM\\venv\\lib\\site-packages\\huggingface_hub\\utils\\_deprecation.py:127: FutureWarning: '__init__' (from 'huggingface_hub.inference_api') is deprecated and will be removed from version '0.19.0'. `InferenceApi` client is deprecated in favor of the more feature-complete `InferenceClient`. Check out this guide to learn how to convert your script to use it: https://huggingface.co/docs/huggingface_hub/guides/inference#legacy-inferenceapi-client.\n",
      "  warnings.warn(warning_message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "llm_huggingface=HuggingFaceHub(repo_id='google/flan-t5-large',model_kwargs={\"temperature\":0,\"max_length\":64})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moscow\n"
     ]
    }
   ],
   "source": [
    "output=llm_huggingface.predict(\"can you tell me capital of russia\")\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NLP is a computer science field that focuses on machine learning and artificial intelligence.\n"
     ]
    }
   ],
   "source": [
    "output=llm_huggingface.predict(\"can you tell me main topic of NLP ,LLM to become expert\")\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "The main topics of NLP and LLM for becoming an expert are:\n",
      "\n",
      "1. Natural Language Processing (NLP):\n",
      "- Text pre-processing and cleaning\n",
      "- Text mining and information extraction\n",
      "- Text classification and sentiment analysis\n",
      "- Machine translation\n",
      "- Speech recognition and synthesis\n",
      "- Dialogue systems\n",
      "\n",
      "2. Legal Language Modeling (LLM):\n",
      "- Legal document classification\n",
      "- Legal information retrieval\n",
      "- Legal text summarization\n",
      "- Legal document understanding\n",
      "- Legal argumentation mining\n",
      "- Legal ontology engineering\n"
     ]
    }
   ],
   "source": [
    "output=llm.predict(\"can you tell me main topic of NLP ,LLM to become expert\")\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prompt templates & LLM Chain\n",
    "\n",
    "from langchain.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Tell me the capital of the India'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Prompt_template=PromptTemplate(input_variables=['country'],\n",
    "template='Tell me the capital of the {country}')\n",
    "\n",
    "Prompt_template.format(country=\"India\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "predict() missing 1 required positional argument: 'text'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\basha\\LLM\\langchain.ipynb Cell 14\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/basha/LLM/langchain.ipynb#X16sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m llm\u001b[39m.\u001b[39;49mpredict(Prompt_template\u001b[39m=\u001b[39;49mPrompt_template)\n",
      "\u001b[1;31mTypeError\u001b[0m: predict() missing 1 required positional argument: 'text'"
     ]
    }
   ],
   "source": [
    "# llm.predict(Prompt_template=Prompt_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import  LLMChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "The capital of India is New Delhi.\n"
     ]
    }
   ],
   "source": [
    "chain=LLMChain(llm=llm,prompt=Prompt_template)\n",
    "print(chain.run(\"india\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#combining multiple chains using simple sequential chain\n",
    "\n",
    "capital_template=PromptTemplate(input_variables=['country'],\n",
    "template=\"Please tell me the capital of the {country}\")\n",
    "\n",
    "capital_chain=LLMChain(llm=llm,prompt=capital_template)\n",
    "famous_template=PromptTemplate(input_variables=['capital'],\n",
    "template=\"suggest me some amazing places to visit in {capital}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "famous_chain=LLMChain(llm=llm,prompt=famous_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Some of the amazing places to visit in Delhi are: \n",
      "\n",
      "1. Qutub Minar: Built in 1193, this red sandstone tower is a UNESCO World Heritage Site and is the tallest minaret in India.\n",
      "\n",
      "2. India Gate: Located in the heart of the city, this war memorial is a symbol of pride and honour.\n",
      "\n",
      "3. Red Fort: The 17th century Mughal fort is a UNESCO World Heritage Site and is one of the most popular tourist attractions in Delhi.\n",
      "\n",
      "4. Jama Masjid: This is the largest mosque in India and a must-visit for its impressive architecture.\n",
      "\n",
      "5. Humayun's Tomb: Built in the 16th century, this is the first garden-tomb in India and a UNESCO World Heritage Site.\n",
      "\n",
      "6. Akshardham Temple: This modern Hindu temple complex is a must-visit for its intricate architecture and religious significance.\n",
      "\n",
      "7. Lotus Temple: This temple is a beautiful structure made of marble, concrete and glass and is a popular tourist attraction.\n",
      "\n",
      "8. Jantar Mantar: This is an astronomical observatory built in the 18th century and is a UNESCO World Heritage Site.\n",
      "\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import SimpleSequentialChain\n",
    "chain=SimpleSequentialChain(chains=[capital_chain,famous_chain])\n",
    "print(chain.run(\"india\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "### sequential chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "capital_template=PromptTemplate(input_variables=['country'],\n",
    "template=\"Please tell me the capital of the {country}\")\n",
    "capital_chain=LLMChain(llm=llm,prompt=capital_template,output_key=\"capital\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "famous_template=PromptTemplate(input_variables=['capital'],\n",
    "template=\"suggest me some amazing places to visit in {capital}\")\n",
    "famous_chain=LLMChain(llm=llm,prompt=famous_template,output_key=\"places\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import SequentialChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain=SequentialChain(chains=[capital_chain,famous_chain],\n",
    "input_variables=['country'],\n",
    "output_variables=['capital','places'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for text-davinci-003 in organization org-C6UE7g5TrYGnzldoxZleVXp8 on requests per min. Limit: 3 / min. Please try again in 20s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing..\n",
      "Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for text-davinci-003 in organization org-C6UE7g5TrYGnzldoxZleVXp8 on requests per min. Limit: 3 / min. Please try again in 20s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing..\n",
      "Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for text-davinci-003 in organization org-C6UE7g5TrYGnzldoxZleVXp8 on requests per min. Limit: 3 / min. Please try again in 20s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing..\n",
      "Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for text-davinci-003 in organization org-C6UE7g5TrYGnzldoxZleVXp8 on requests per min. Limit: 3 / min. Please try again in 20s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing..\n",
      "Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised RateLimitError: Rate limit reached for text-davinci-003 in organization org-C6UE7g5TrYGnzldoxZleVXp8 on requests per min. Limit: 3 / min. Please try again in 20s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing..\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'country': 'india',\n",
       " 'capital': '\\n\\nThe capital of India is New Delhi.',\n",
       " 'places': \" \\n\\n1. Red Fort: Red Fort is a 17th-century fort complex built by Mughal Emperor Shah Jahan in Delhi. It is one of the most popular tourist spots in the city and is a must-visit for any traveler.\\n\\n2. India Gate: India Gate is a war memorial located in the heart of New Delhi. It is a popular tourist spot and is one of the most iconic structures of the city.\\n\\n3. Qutub Minar: Qutub Minar is a 73-meter tall tower located in Mehrauli, Delhi. It is one of the most popular tourist spots in the city and is a must-visit for any traveler.\\n\\n4. Humayun's Tomb: Humayun's Tomb is a mausoleum built in 1570 by the Mughal Emperor Humayun. It is one of the most popular tourist spots in the city and is a must-visit for any traveler.\\n\\n5. Jama Masjid: Jama Masjid is a 17th-century mosque located in Old Delhi. It is one of the largest mosques in India and is a must-visit for any traveler.\\n\\n6. Lotus Temple: Lotus\"}"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain({'country':'india'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#chatmodels with cahtopen AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import HumanMessage,SystemMessage,AIMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "chatllm=ChatOpenAI(openai_api_key=os.environ['OPEN_API_KEY'],temperature=0.6,model='gpt-3.5-turbo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='1. \"Why did the AI go on a diet? It wanted to byte the bullet and shed some virtual pounds!\"\\n\\n2. \"You know you\\'re in trouble when an AI starts giving you relationship advice. It\\'s like getting tips from a toaster on finding the perfect toast!\"\\n\\n3. \"Why did the AI become a stand-up comedian? It realized it had an infinite database of jokes, but zero social skills!\"\\n\\n4. \"What do you call an AI that tells bad jokes? A pun-intended!\"\\n\\n5. \"Why did the AI cross the road? To optimize its pedestrian detection algorithm!\"\\n\\n6. \"Why did the AI fail at singing? It couldn\\'t find the right pitch, but it sure had plenty of algorithms!\"\\n\\n7. \"What did the AI say to the programmer? \\'I love you with all my cache!\\'\"\\n\\n8. \"Why did the AI get a job at the bakery? It kneaded the dough!\"\\n\\n9. \"Why did the AI join a band? It wanted to be the ultimate master of artificial harmonies!\"\\n\\n10. \"What do you call an AI that loves to dance? An algorhythm!\"'\n"
     ]
    }
   ],
   "source": [
    "print(chatllm([\n",
    "    SystemMessage(content=\"you are a comedian AI assistent\"),\n",
    "    HumanMessage(content=\"Please provide some comedy punchlines on AI\")\n",
    "    ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prompttemplate + LLM + Output Parsers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts.chat import ChatPromptTemplate\n",
    "\n",
    "from langchain.schema import BaseOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "class commaseperaatedoutput(BaseOutputParser):\n",
    "    def parse(self,text:str):\n",
    "        return text.strip().split(\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "template=\"You are a helpful assistant. When te user gives any input , you should generate 5 words which should be comma seperated\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "human_template=\"{text}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "chatprompt=ChatPromptTemplate.from_messages([\n",
    "    (\"system\",template),(\"human\",human_template)\n",
    "                                            ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain=chatprompt|chatllm|commaseperaatedoutput()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['smart', ' clever', ' brilliant', ' knowledgeable', ' quick-witted']"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"text\":\"intelligent\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
